---
title:  "스크래피를 사용한 크롤링(1)"
excerpt: "파이썬으로 만들어진 대표적인 크롤러 : 스크래피"
categories:
  - Python
tags:
  - WebCrawling, Scrapy, Python, SelfStudy
---

#### 스크래피의 장정
1. 스크랩할 항목 유형별 클래스를 만들 수 있음
2. 수집한 데이터를 원하는 대로 편집이 가능
3. 서버에 연동하기 위해 기능을 확장할 수 있음
4. 크롤링 결과를 JSON, XML, CSV 등의 형식으로 내보낼 수 있음
5. 손상된 HTML파일을 분석할 수 있음
-----------------------------------------------
### 1. 스크래피 설치하하기
- Termianl창에 "pip install scrapy" 명령 실행
- 설치가 완료된지 확인을 위해 "scrapy"명령을 한 번 더 실행시킨다.
  아래와 같이 나온다면 설치가 완료된 것

<img src="https://user-images.githubusercontent.com/87592790/189274567-085348de-4828-436d-ab9a-1a5cd3115451.png" width="500" height="300">

### 2. 스크래피 프로젝트 생성 : startproject
- Terminal에 "scrapy startproject <프로젝트이름>"명령을 실행하면 명령을 실행한 경로에 새로운 프로젝트가 생성된다. 
- 한빛미디어 홈페이지에 책을 크로릴할 예정으로 hanbit_crawling이라고 지었음

<img src="https://user-images.githubusercontent.com/87592790/189276099-6e504380-f9e6-45b8-87da-7810350a1394.png" width="600" height="100">

<img src="https://user-images.githubusercontent.com/87592790/189276199-e5ab508c-58f7-4c8d-9b52-22750aa67826.png" width="300" height="300">

### 3. 아이템 설정하기
- 크롤링하는 이유는 기본적으로 비정형 데이터인 웹페이지를 목적에 맞게 일정한 형태로 가공하기 위해 사용할 것이다
- 프로제트 안에 item.py의 수정을 통해 가져올 정보를 설정한다.

#### [ 크롤링할_할목_이름 = scrapy.Field() ] 형식으로 아이템을 설정
```python
class HanbitCrawlingItem(scrapy.Item):
    
    # 책 이름
    book_title = scrapy.Field()
    
    # 저자 이름
    book_author = scrapy.Field()
    
    # 번역자 이름
    book_translator = scrapy.Field()
    
    # 출간일
    book_pub_date = scrapy.Field()
    
    # ISBN
    book_isbn = scrapy.Field()
    pass
```



